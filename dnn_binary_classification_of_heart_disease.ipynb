{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9deac9",
   "metadata": {},
   "source": [
    "# DNNで二値分類をする\n",
    "keras_tunerを使用して、ハイパーパラメータのチューニングを行う。\n",
    "\n",
    "### 大まかな処理の流れ\n",
    "1. データの取り込み\n",
    "2. データの整形（トレーニングデータとテストデータを作成）\n",
    "3. モデルの定義\n",
    "4. チューナーをインスタンス化して、ハイパーパラメータのチューニングする\n",
    "5. チューニングしたハイパーパラメータでモデルを作成し、トレーニングする\n",
    "6. 作成したモデルを保存する\n",
    "7. 保存したモデルをお読み込み、予測したいデータで予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e4751",
   "metadata": {},
   "source": [
    "## 使用ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acc5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import FeatureSpace\n",
    "import keras_tuner\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e3983",
   "metadata": {},
   "source": [
    "## 1. データの取り込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad8a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd2dcd",
   "metadata": {},
   "source": [
    "## 2. データの確認\n",
    "省略可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b83dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e51d7",
   "metadata": {},
   "source": [
    "## 3. トレーニングデータと検証データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00734aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームから検証用としてランダムに20％取り出す\n",
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームからデータセットに変換\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの中身の確認\n",
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f69aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c88980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 構造化データの前処理とエンコードを行う\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        # integerとしてエンコードされたカテゴリー特徴\n",
    "        \"sex\": \"integer_categorical\",\n",
    "        \"cp\": \"integer_categorical\",\n",
    "        \"fbs\": \"integer_categorical\",\n",
    "        \"restecg\": \"integer_categorical\",\n",
    "        \"exang\": \"integer_categorical\",\n",
    "        \"ca\": \"integer_categorical\",\n",
    "        # stringとしてエンコードされたカテゴリー特徴\n",
    "        \"thal\": \"string_categorical\",\n",
    "        # 離散化する数値的特徴\n",
    "        \"age\": \"float_discretized\",\n",
    "        # 正規化する数値的特徴\n",
    "        \"trestbps\": \"float_normalized\",\n",
    "        \"chol\": \"float_normalized\",\n",
    "        \"thalach\": \"float_normalized\",\n",
    "        \"oldpeak\": \"float_normalized\",\n",
    "        \"slope\": \"float_normalized\",\n",
    "    },\n",
    "    # 交差する特徴の組み合わせリスト。\n",
    "    # 特徴は、結合された値を固定長ベクトルにハッシュすることによって「交差」する。\n",
    "    crosses=[(\"sex\", \"age\"), (\"thal\", \"ca\")],\n",
    "    # 交差した特徴をハッシュするためのデフォルトのベクトルサイズ\n",
    "    # デフォルトは32\n",
    "    crossing_dim=32,\n",
    "    # \"concat\"または\"dict\"。\n",
    "    # \"concat\"では、すべての特徴が 1 つのベクトルに連結される。\n",
    "    # \"dict\"では、個別にエンコードされた特徴のdictを返す (入力キーと同じキーを使用)。\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21d7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータセットから１つ取り出して確認\n",
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_parallel_callsで処理を並列化する。\n",
    "# tf.data.AUTOTUNEは並列度をランタイムで良い感じに決めてくれる。\n",
    "preprocessed_train_ds = train_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "# prefetchはGPUが計算している間にBatchデータをCPU側で用意しておく機能\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_val_ds = val_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(preprocessed_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c5d57",
   "metadata": {},
   "source": [
    "## 4. モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # 入力層\n",
    "    model.add(tf.keras.Input(tensor=encoded_features))\n",
    "\n",
    "    # 隠れ層\n",
    "    hp_n_hidden_layers = hp.Int(\"n_hidden_layers\", min_value=1, max_value=10) # max_valueに最適化した最大隠れ層数を指定\n",
    "    for i in range(hp_n_hidden_layers):\n",
    "        hp_units = hp.Int(\"units_%d\" % (i + 1), min_value=32, max_value=512, step=32)\n",
    "        hp_activation = hp.Choice(\"activation_%d\" % (i + 1), [\"relu\", \"tanh\"]) # 活性化関数\n",
    "        model.add(tf.keras.layers.Dense(hp_units, activation=hp_activation))\n",
    "        model.add(tf.keras.layers.Dropout(hp.Choice(name=\"dropout_%d\" % (i + 1), values=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))) # ドロップアウト率\n",
    "\n",
    "    # 出力層\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # 最適化アルゴリズム、損失関数、評価関数を指定してコンパイル\n",
    "    # 最適化アルゴリズムを最適化\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(\n",
    "        # 最適化アルゴリズム\n",
    "        optimizer=tf.keras.optimizers.Adam(hp_learning_rate),\n",
    "        # 損失関数\n",
    "        # 二値分類→binary_crossentropy、多クラス単一ラベル分類→categorical_crossentropy\n",
    "        # 多クラス多ラベル分類→binary_crossentropy、回帰問題（任意の値）→mse、回帰問題（０～１の値）→mse / binary_crossentropy\n",
    "        loss=\"binary_crossentropy\",\n",
    "        # 評価関数\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeefbf1",
   "metadata": {},
   "source": [
    "## 5. チューナーをインスタンス化してハイパーパラメータのチューニングを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09df7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チューナーのインスタンス化\n",
    "# RandomSearch、Hyperband、BayesianOptimization、Sklearnがある\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\", # 最適化する目標の名前：accuracy, loss, val_accuracy, val_loss\n",
    "    max_trials=50, # チューニングする試行数\n",
    "    executions_per_trial=2, # 各トライアルに構築して適合させる必要があるモデルの数\n",
    "    overwrite=True,\n",
    "    directory=\"./\",\n",
    "    project_name=\"dnn_keras_tuner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcdadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証損失が特定の値に達した時に、トレーニングを早期に停止するためのコールバック関数\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f66a2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cur_dir_path = %pwd\n",
    "tuner.search(\n",
    "    preprocessed_train_ds, # トレーニングデータセット\n",
    "    epochs=50, # 学習の繰り返す数\n",
    "    validation_data=preprocessed_val_ds, # 検証データセット\n",
    "    callbacks=[stop_early], # 早期停止する場合のコールバック関数\n",
    ")\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fdc74",
   "metadata": {},
   "source": [
    "## 6. モデルをトレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccca574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適なハイパーパラメータ\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "# 最適なハイパーパラメータでモデルの作成\n",
    "model = tuner.hypermodel.build(best_hp)\n",
    "# モデルのトレーニング\n",
    "model.fit(preprocessed_train_ds, epochs=50, validation_data=preprocessed_val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7d303",
   "metadata": {},
   "source": [
    "## 7. モデルの保存と概要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85959125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "model.save(\"model\")\n",
    "# モデルの概要\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チューニングの該当\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4458e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = tf.keras.models.load_model('model')\n",
    "\n",
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\"\n",
    "}\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "\n",
    "# 予測\n",
    "output = model.predict(feature_space(input_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 離散化を行う関数\n",
    "def discretize(proba):\n",
    "    threshold = np.array([0.5]) # 0か1かを分ける閾値を0.5に設定\n",
    "    discretized = (proba >= threshold).astype(int) # 閾値未満で0、以上で1に変換\n",
    "    return discretized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果\n",
    "print(np.array(discretize(output)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
